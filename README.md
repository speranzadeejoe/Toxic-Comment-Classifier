# Toxic-Comment-Classifier


---

# **Toxic Comment Classifier**

This project is a simple web app that checks if a comment is **toxic** or **non-toxic** using Machine Learning.

* **Frontend**: HTML, CSS, JavaScript
* **Backend**: Python Flask API
* **Model**: Logistic Regression with TF-IDF

---
# **Sample Output**
<img width="1919" height="1005" alt="image" src="https://github.com/user-attachments/assets/b4a67655-0482-450f-b523-d1e0a610c8f5" />



## 📂 Project Files

* `app.py` – Flask backend
* `model.pkl` – Trained machine learning model
* `vectorizer.pkl` – TF-IDF vectorizer
* `templates/index.html` – Frontend page

---

## 🚀 How to Run

1. **Clone this repository**
   `git clone https://github.com/your-username/toxic-comment-classifier.git`

2. **Go into the project folder**
   `cd toxic-comment-classifier`

3. **Create a virtual environment**
   `python -m venv venv`
   `venv\Scripts\activate` (for Windows)

4. **Install libraries**
   `pip install flask scikit-learn numpy`

5. **Start the Flask server**
   `python app.py`

6. **Open your browser** and visit:
   `http://127.0.0.1:5000/`

7. **Enter a comment** and check the result.

---

## 📊 Model Training

* Dataset used: [Kaggle - Toxic Comment Dataset](https://www.kaggle.com/datasets/akashsuper2000/toxic-comment-classification)
* Model used: Logistic Regression + TF-IDF

---

## 👩‍💻 Created By

**Speranza Deejoe**

---

