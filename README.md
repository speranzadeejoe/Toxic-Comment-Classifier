# Toxic-Comment-Classifier


---

# **Toxic Comment Classifier**

This project is a simple web app that checks if a comment is **toxic** or **non-toxic** using Machine Learning.

* **Frontend**: HTML, CSS, JavaScript
* **Backend**: Python Flask API
* **Model**: Logistic Regression with TF-IDF

---
# **Sample Output**
<img width="1919" height="1005" alt="image" src="https://github.com/user-attachments/assets/b4a67655-0482-450f-b523-d1e0a610c8f5" />



## ğŸ“‚ Project Files

* `app.py` â€“ Flask backend
* `model.pkl` â€“ Trained machine learning model
* `vectorizer.pkl` â€“ TF-IDF vectorizer
* `templates/index.html` â€“ Frontend page

---

## ğŸš€ How to Run

1. **Clone this repository**
   `git clone https://github.com/your-username/toxic-comment-classifier.git`

2. **Go into the project folder**
   `cd toxic-comment-classifier`

3. **Create a virtual environment**
   `python -m venv venv`
   `venv\Scripts\activate` (for Windows)

4. **Install libraries**
   `pip install flask scikit-learn numpy`

5. **Start the Flask server**
   `python app.py`

6. **Open your browser** and visit:
   `http://127.0.0.1:5000/`

7. **Enter a comment** and check the result.

---

## ğŸ“Š Model Training

* Dataset used: [Kaggle - Toxic Comment Dataset](https://www.kaggle.com/datasets/akashsuper2000/toxic-comment-classification)
* Model used: Logistic Regression + TF-IDF

---

## ğŸ‘©â€ğŸ’» Created By

**Speranza Deejoe**

---

